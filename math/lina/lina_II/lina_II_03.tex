\section{Normalformen}
\setcounter{subsection}{16}
\subsection{Skript 17}
%\setcounter{subenvironmentnumber}{-1}

\setcounter{subsubsection}{8}
\subsubsection{Eigenwerte und Eigenvektoren}
Sei $ V $ ein $ n $-dim $ K $-VR über

\begin{subdefinition}
	Sei $ T \in \mathcal{L(V, V)}  $ und $ c \in K $.
	\begin{enumerate}[label=(\alph*)]
		\item $ c $ ist ein Eigenwert für $ T $, falls $ \exists \alpha \in V $, $ \alpha \neq 0 $ so, dass
			\[
				T(\alpha) = c \alpha
			\]
		\item sei $ \alpha \in V $ so, dass
			\[
				T(\alpha) = c\alpha
			\]
			Dann ist $ \alpha $ \textbf{ein Eigenvektor}
		\item $ W_c \coloneqq \left\{ \alpha \in V, T(\alpha) \right\}  $ 
			der \textbf{Eigenraum} zu $ c $
	\end{enumerate}
\end{subdefinition}

\begin{subnote}
	\[
		W_c = \Kern \left( cI - T \right) 
	\]
	weil
	\[
		W_c = \left\{ \alpha : c\alpha - T(\alpha) = 0 \right\} 
	\]
\end{subnote}

\begin{subtheorem}
	Wir folgern aus Satz \ref{2.16.8} und Bem. \ref{3.17.2} und Def. \ref{3.17.1}:\\
	Sei $ T \in \mathcal{L} (V, V) $, $ c \in K $.
	Folgende Aussagen sind äquivalent:
	\begin{enumerate}[label=(\roman*)]
		\item $ c $ ist ein Eigenwert von $ T $ 
		\item $ \left( cI - T \right)  $ ist \textbf{nicht} invertierbar
		\item $ \det\left( cI - T \right) = 0 $
	\end{enumerate}
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.17.3}]
	\begin{description}
		\item[``(i) $ \implies  $ (ii)'':] wenn $ c $ Eigenwert von $ T $, dann existiert ein $ \alpha \in V $ mit $ \alpha \neq 0 $, so dass $ \left( cI - T \right) (\alpha) = 0 $, somit Kern nicht trivial, also $ \left( cI - T \right)  $ nicht invertierbar
		\item[``(ii) $ \implies  $ (iii)'':] \ldots
		\item[``(iii) $ \implies  $ (i)'':] $ \det\left( cI - T \right) = 0 $ bedeutet $ ( cI - T) $ nicht invertierbar, also Kern trivial, also existiert kein $ \alpha \in V $, \ldots vllt. auch einfacher mit Widerspruch \qed
	\end{description}
\end{subproof*}

\begin{subtheorem}
	$ \det\left( cI - T \right)  $ ist ein normiertes Polynom von Grad $ n $.
	Die Eigenwerte von $ T $ sind also seine NS in $ K $.
	Insbesondere hat $ T $ \textbf{höchstens} $ n $ Eigenwerte in $ K $
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.17.4}]
	Sei $ \mathcal{B}  $ eine geordnete Basis für $ V $, $ A \coloneqq [T]_{\mathcal{B} }  $.
	Es ist $ xI_n - A = \left[ xI - T \right]_{\mathcal{B} }  $ 
	\begin{align*}
		B &\coloneqq xI_n - A \\
		~ &= \begin{pmatrix} x & 0 & \hdots & 0 \\ 0 & x & & \vdots \\ \vdots & & \ddots & 0 \\ 0 & \hdots & 0 & x \end{pmatrix} - A \\
		~ &= \begin{pmatrix} x -a_{11} & \hdots & -a_{1n} \\ -a_{21} & \ddots & \vdots \\ \vdots & & x - a_{nn}  \end{pmatrix}  \\
	\end{align*}
	wobei $ A_{ij} = a_{ij}  $ 
	Also $ b_{ii} = (x - a_{i i}) $, $ \deg b_{i i} = 1 $.
	Die Einträge von $ B $ sind 0 Polynome, Polynome von Grad 0 oder 1.
	Berechne
	\[
		\det B = \sum_{\tau \in S_n}^{} \Signum \tau b_{1 \tau(1)}  \dotsb b_{n \tau(n)} 
	\]
	\[
		\deg\left( b_{1\tau(1)} \dotsb b_{n\tau(n)}  \right) = \left| \left\{ i \in \left\{ 1, \dotsc, n \right\} : \tau(i) = i \right\}  \right| 
	\]
	Also ist
	\[
		\prod_{i = 1}^{n} \left( x - a_{i i}  \right) 
	\]
	der \textbf{einzige} Term von Grad $ n $, und somit ist der \textbf{Hauptterm}!
	Also
	\[
		\deg\left( \det B \right) = n
	\]
	und ist normiert \qed
\end{subproof*}

\begin{subdefinition}
	Sei $ A \in M_{n \times n} (K) $ und $ c \in K $, $ c $ ist $ c $ ist ein \textbf{Eigenwert von $ A $} falls $ \det\left( cI - A \right) = 0 $.
\end{subdefinition}

\begin{subdefinition}
	$ f(x) \coloneqq \det(xI_n - A) $ für $ A \in M_{n \times n} (K) $
	heißt das \textbf{Charakteristische} Polynom von $ A $
\end{subdefinition}

\begin{sublemma}
	Ähnliche Matrizen haben das gleiche charakteristische Polynom
\end{sublemma}
\begin{subproof*}[Lemma \ref{3.17.7}]
	\[
		B = P^{-1} A P
	\]
	\begin{align*}
		\det\left( xI - B \right) &= \det\left( xI - P^{-1} A P \right)  \\
		~& = \det \left( P^{-1} \left( xI - A \right) ^{P}  \right) \\
		~& = \det P^{-1} \det\left( xI - A \right) \det \left( P \right) \\
		~& = \det\left( xI - A \right) \qed
	\end{align*}
\end{subproof*}

\begin{subdefinition}
	Sei $ V $ endlich dimensional, $ T \in \mathcal{L} \left( V, V \right)  $ 
	\[
		\operatorname{Char Pol}(T) = \operatorname{Char Pol}\left( [T]_{\mathcal{B} }  \right) 
	\]
	für irgendeine geordnete Basis $ \mathcal{B}  $ von $ V $
\end{subdefinition}

\begin{subexample}
	\begin{enumerate}[label=(\arabic*)]
		\item 
			\[
				A = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} \in M_{2 \times 2} (\R ), \det\left( xI - A \right) = x^2 + 1
			\]
			hat keine reelle NS, also hat $ A $ keine reelle Eigenwerte
		\item
			\[
				A = \begin{pmatrix} 3 & 1 & -1 \\ 2 & 2 & -1 \\ 2 & 2 & 0 \end{pmatrix} \in M_{3 \times 3} \left( \R  \right) 
			\]
			\[
				\left| xI - A \right| = x^3 - 5x^2 + 8x - 4 = \left( x - 1 \right) \left( x - 2 \right) ^2
			\]
			Eigenwerte $ c = 1, c = 2 $\\
			Berechne Eigenvektoren
			\begin{itemize}
				\item $ c = 1 $ 
					$ \Kern \left( A - I \right) \coloneqq W_1 $ 
					\[
						\left( A - I \right) = \begin{pmatrix} 2 & 1 & -1 \\ 2 & 1 & -1 \\ 2 & 1 & -1 \end{pmatrix} 
					\]
					$ \implies \Rang(A) = 2, \dim W_1 = 1 $
					Wir wollen eine Basis für $ W_1 $ finden, löse
					\[
						(A - 1) \begin{pmatrix} x_1 \\ x_2 \\x_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} 
					\]
					Hier $ \alpha_1 = \left( 1, 0, 2 \right) \neq 0 $ ist eine Lösung, und
					$ \left\{ \alpha_1 \right\}  $ ist eine Basis für $ W_1 $ 
				\item $ c = 2 $ $ W_2 $?
					\[
						\left( A - 2I \right) = \begin{pmatrix} 1 & 1 & -1 \\ 2 & 0 & -1 \\ 2 & 2 & -2 \end{pmatrix} 
					\]
					hat $ \Rang(A) = 2 $ $ \implies \dim W_2 = 1 $ 
					Lösung wie oben
					$ \alpha_2 = (1, 1, 2) \neq 0 $ und $ \left\{ \alpha_2 \right\}  $ eine Basis
			\end{itemize}
	\end{enumerate}
\end{subexample}

\begin{sublemma}
	Sei $ T \in \mathcal{L} \left( V, V \right)  $ seien $ c_i $ für $ i = 1, \dotsc, k $ Eigenwerte von $ T $ (in $ K $) und $ \forall i \neq j $, $ i, j \in \left\{ 1, \dotsc, k \right\} : c_i \neq c_j $ 
	Sei $ v_i \neq 0 $, $ v_i \in V $ Eigenvektor zum Eigenwert $ c_i $.
	Dann ist $ \left\{ v_1, \dotsc, v_k \right\} $ linear Unabhängig
\end{sublemma}
\begin{subproof*}[Lemma \ref{3.17.10}]
	Wir führen Induktion nach $ k $ 
	\begin{description}
		\item[I.A.] $ k = 2 $: wenn $ v_2 = cv_1 $ dann ist $ v_2 \in W_{c_1}  $, dann ist $ v_2 $ Eigenvektor zu $ c_1 $ $ \bot $
		\item[I.V.] Für $ k -1 $ 
		\item[I.S.] Seien $ v_1, \dotsc, v_k $ linear abhängig\\
			\textbf{Bem.:} Sei $ v \in V $, $ v \neq 0 $ kann $ v $ \textbf{nicht} Eigenvektor sein zu verschiedenen Eigenwerten!\\
			\OE{}
			\[
				v_k = \sum_{i=1}^{k - 1} v_i
			\]
			Wir berechnen
			\[
				T(v_k) = c_k v_k = c_k \sum_{i=1}^{k - 1} v_i
			\]
			\[
				= T(v_k) = \sum_{i=1}^{k - 1} T(v_i) = \sum_{i=1}^{k - 1} c_i v_i
			\]
			\[
				\implies c_k \sum_{i=1}^{k - 1} v_i = \sum_{i=1}^{k - 1} c_i v_i
			\]
			\[
				\implies \sum_{i=1}^{k - 1} \left( c_k - c_i \right) v_i = 0.
			\]
			Aus I.V. folgt $ c_k - ci = 0 $ $ \forall i = 1, \dotsc, k - 1 $
	\end{description}
\end{subproof*}

\begin{subcorollary}
	 Sei $ \dim V = n $, $ T \in \mathcal{L} \left( V, V \right)  $.
	 Wir nehmen an, dass $ T $ {\color{gadse-orange}$ n $ verschiedene} Eigenwerte $ d_1, \dotsc, d_n \in K $ hat.
	 Dann hat $ V $ eine Basis $ \mathcal{D}  $ bestehend aus Eigenvektoren für $ T $.\qed
\end{subcorollary}

\begin{subdefinition}
	Sei $ \dim V = n $, $ T \in \mathcal{L} \left( V, V \right)  $.
	$ T $ ist \textbf{diagonalisierbar} über $ K $, falls $ V $ eine Basis, bestehend aus Eigenvektoren von $ T $ hat.
\end{subdefinition}

\begin{subnote}
	$ d_1, \dotsc, d_n \in K $ $ n $-verschiedene Eigenwerte von $ T $, $ \mathcal{D}  $ die geordnete Basis wie im Korollar \ref{3.17.11}, dann ist
	\[
		[T]_{\mathcal{D} } = \begin{pmatrix} d_1 & & 0 \\ & \ddots & \\ 0 & & d_n \end{pmatrix} 
	\]
\end{subnote}

\subsection{Skript 18}
\begin{subcorollary}[Verallgemeinerung Lemma \ref{3.17.10}]
$ \dim V = n $, $ T \in \mathcal{L} \left( V, V \right)  $, $ d_1, \dotsc, d_k \in K $ verschiedene Eigenwerte von $ T $ für $ i \in \left\{ 1, \dotsc, k \right\}  $ 
Sei
\[
	\mathcal{B} _i \subseteq W_{d_i} 
\]
linear unabhängig.
Dann ist $ \mathcal{B} = \bigcupdot_{i \in  I} B_i $
\end{subcorollary}
\begin{subproof*}[Korollar \ref{3.18.1}]
	\[
		L \coloneqq  \left\{ v_1, \dotsc, v_l \right\} \subseteq \mathcal{B} 
	\]
	Betrachte
	\[
		\sum_{j=1}^{l} c_j v_j
	\]
	Setze
	\[
		L_i \coloneqq  L \cap \mathcal{B} _i
	\]
	und setze
	\begin{equation}
		\label{eq:3.18.1.1}
		\tag{$ * $}
		\alpha_i \coloneqq \sum_{v_j \in L_i}^{} c_j v_j \in W_{d_i} 
	\end{equation}
	(Konvention falls $ L_i = \OO  $, setzte $ \alpha_i = 0 $).
	Also wenn
	\[
		0 = \sum_{j=1}^{l} c_j v_j \implies \sum_{i=1}^{k} \alpha_i = 0
	\]
	\textbf{Beh.:}
	Wenn 
	\[
		\sum_{i=1}^{k} \alpha_i = 0
	\]
	dann ist $ \alpha_i = 0 \quad \forall i = 1, \dotsc, k $\\
	\textbf{Bew. der Beh.} sonst
	\[
		\alpha_i \neq 0,
	\]
	Eigenvektoren zu verschiedenen Eigenwerten und linear abhängig.
	Widerspruch zu \ref{3.17.10} zurück in \eqref{eq:3.18.1.1} $ \alpha_1 = 0 \implies  $ 
	\[
		\sum_{v_j \in L_i}^{} c_j v_j = 0
	\]
	aber $ v_j $ sind per Annahme linear unabhängig.
	Also $ c_j = 0 ~ \forall j = 1, \dotsc, k $\qed
\end{subproof*}

\begin{subtheorem}[Verallgemeinerung von Korollar \ref{3.17.11}]
	Sei $ \dim V = n $, $ T \in \mathcal{L} \left( V, V \right) , d_1, \dotsc, d_k \in K $ die verschiedenen Eigenwerte von $ T $ in $ K $.\\
	Es gilt:
	$ T $ ist diagonalisierbar über $ K $ genau dann, wenn
	\[
		\sum_{j=1}^{k} \dim W_{d_j}  = n
	\]
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.18.2}]
	\begin{description}
		\item[``$ \impliedby  $'':] Sei $ \mathcal{B} _j $ eine Basis für $ W_{d_j}  $ für jedes $ j = 1, \dotsc, k $ setze 
			\[
				B = \bigcupdot_{j = 1} ^{k} \mathcal{B} _j
			\]
			Korollar \ref{3.18.1} $ \implies  $ $ \mathcal{B}  $ linear unabängig
		\item[``$ \implies  $'':]
			Sei $ \mathcal{B}  $ eine Basis für $ V $ von Eigenvektoren von $ T $.
			Setze $ \mathcal{B} _j = \mathcal{B} \cap W_{d_j}  $ Also ist
			\[
				\mathcal{B} = \bigcupdot_{j = 1} ^{k} B_j
			\]
			\[
				\left| \mathcal{B}  \right| = n
			\]
			Setze 
			\[
				l_j = \left| \mathcal{B} _j \right| 
			\]
			also 
			\[
				n = \sum_{j=1}^{k} l_j
			\]
			\textbf{Beh.:}
			$ l_j = \dim W_{d_j}  $ 
			Es ist klar, dass
			\[
				l_j \leq \dim W_{d_j} 
			\]
			Wenn $ l_i < \dim W_{d_i}  $, dann $ \exists \beta \in W_{d_i}  $ so, dass
			\[
				\mathcal{B} _i^\prime = \mathcal{B} _i \cup \left\{ \beta \right\} 
			\]
			linear unabhängig ist.
			Aber dann
			\[
				\mathcal{B} ^\prime = \mathcal{B} \cup \left\{ \beta \right\} 
			\]
			linear unabhängig!
			Aber $ \left| \mathcal{B}^\prime \right| = n + 1 $ $ \bot $\qed
	\end{description}
\end{subproof*}

Sei $ \mathcal{D}  $ die Basis
\[
	[T]_{\mathcal{D} } = \begin{pmatrix} d_1 \\ & \ddots \\ & & d_1 \\ &&& \ddots \end{pmatrix} 
\]
Wobei $ \forall i = 1, \dotsc, k $, $ d_i $ erscheint $ l_i \coloneqq \dim W_{d_i} $ mal

Mit diesem Ansatz
\begin{equation}
	\label{eq:3.18.1}
	\tag{$ \dag $}
	\operatorname{Char Pol}(T) = \operatorname{Char Pol}\left( [T]_{\mathcal{D} }  \right) = \prod_{i = 1}^{k} \left( x - d_i \right) ^{l_i}  
\end{equation}

Umgekehrt, sei $ T \in \mathcal{L} \left( V, V \right) , \operatorname{Char Pol}(T) $ genau so, wie in \eqref{eq:3.18.1} ist, dann ist $ T $ diagonalisierbar (wegen Satz \ref{3.18.2}) wir haben bewiesen

\begin{subtheorem}
	Sei $ \dim V = n, T \in \mathcal{L} \left( V, V \right)  $.
	Es gilt: $ T $ ist diagonalisierbar genau dann wenn $ \operatorname{Char Pol}(T) = \prod_{i = 1}^{k} (x - d_i)^{l_i}   $.

	\textbf{Terminologie:} $ \dim W_d $ wird auch als $ d \in K $ Eigenwert \textbf{geometrische Vielfachheit} der Eigenwerte $ d $ genannt

	$ T $ ist diagonalisierbar (über $ K $) genau dann wenn $ \operatorname{Char Pol}(T) $ als Produkt von lin. Faktoren über $ K $ erfüllt \textbf{und} die algebraische Vielfachheit jeder Nullstelle ist gleich geometrischer Vielfachheit jeder Eigenwerte
\end{subtheorem}

\begin{subtheorem}
	Sei $ \dim V = n $, $ T \in \mathcal{L} \left( V, V \right)  $, $ d \in K $. Eigenwerte von $ T $ mit Vielfachheit $ \mu $.
	Es gilt: $ l \coloneqq \dim \left( W_d \right) \leq \mu $
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.18.4}]
	Sei $ \left( \alpha_1, \dotsc, \alpha_l \right)  $ eine Basis für $ W_d $, ergänze $ \mathcal{B} = \left( \alpha_1, \dotsc, \alpha_l, \alpha_{l + 1} , \dotsc, \alpha_n \right)  $ zur Basis von $ V $. Berechne
	\[
		A \coloneqq [T]_{\mathcal{B} }
		= \begin{pmatrix} d & & 0 \\ & \ddots & & & B & ~ \\ 0 & & d \\ \\ & 0 & & & C \\ ~  \end{pmatrix} 
	\]
	\[
		\det(xI - A)
		= \begin{pmatrix} x - d & & 0 \\ & \ddots & & & -B & ~ \\ 0 & & x - d \\ \\ & 0 & & & xI -C \\ ~  \end{pmatrix} 
		\overset{\text{ÜB} }{=} (x - d)^{l} \det (xI - c)
	\]
	Dies impliziert $ l \leq \mu $\qed
\end{subproof*}

\begin{subexample}
	\[
		A = \begin{pmatrix} 5 & - 6 & - 6 \\ -1 & 4 & 2 \\ 3 & - 6 & -4 \end{pmatrix} 
	\]
	über $ \R  $ 
	$ \operatorname{Char Pol} = (x - 1)(x - 2)^2 $ 
	\[
		d_1 = 1
	\]
	\[
		A = \begin{pmatrix} 4 & - 6 & - 6 \\ -1 & 3 & 2 \\ 3 & - 6 & -5 \end{pmatrix} 
	\]
	$ \Rang \left( A - I \right) = 2 $ 
	\[
		d_2 = 2
	\]
	\[
		A = \begin{pmatrix} 3 & - 6 & - 6 \\ -2 & 3 & 2 \\ 3 & - 6 & -6 \end{pmatrix} 
	\]
	$ \Rang(A - 2I) = 1 $ 
	Also $ \dim W_{d_1} = 1 $, $ \dim W_{d_2} = 2 $, also $ \dim W_{d_1} + \dim W_{d_2} = 3 $, also $ T $ diagonal und
	\[
		[T]_{\mathcal{D} } = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{pmatrix} \qed
	\]
\end{subexample}

\subsection{Skript 19}
\setcounter{subsubsection}{9}
\subsubsection{Annihilator Ideal}
$ \dim V = n, T \in \mathcal{L} \left( V, V \right) , V $ $ K $-Vektorraum

\begin{subproposition}
	Es gelten
	\begin{enumerate}[label=(\arabic*)]
		\item $ \mathcal{A} (T) \coloneqq  \left\{ p \in K[x]; p(T) = 0 \right\}  $ ist ein Ideal
		\item $ \mathcal{A} (T) \neq \left\{ 0 \right\}  $
	\end{enumerate}
\end{subproposition}
\begin{subproof*}[Proposition \ref{3.19.1}]
	\begin{enumerate}[label=(\arabic*)]
		\item $ ( p + q ) (T) = p(T) + q(T) $ und $ \forall p, q \in K[x] $ $ (pq) (T) = p(T) q(T) $ (1) folgt.
		\item Betrachte die $ n^2 + 1 $ Elemente in $ \mathcal{L} \left( V, V \right)  $.
			\[
				I, T, T^2, \dotsc, T^{n^2} \in \mathcal{L} (V, V)
			\]
			Aber $ \dim \mathcal{L} (V, V) = n^2 $ Also sind die linear abhängig\\
			i.e. $ \exists c_0, \dotsc, c_{n^2} \in K $.
			\[
				c_0I + c_1T + \dotsb + c_{n^2} T^{n^2} = 0
			\]
			und die $ c_i $ sind \textbf{nicht}alle gleich 0.
			Also das Polynom
			\[
				c_0 + c_1x + \dotsb + c_{n^2} x^{n^2} = g(x) \neq 0
			\]
			$ g(x) \in \mathcal{A} (T) $ \qed
	\end{enumerate}
\end{subproof*}

\begin{subdefinition}
	$ \mathcal{A} (T) $ ist \textbf{annihilator Ideal}.
	Der (eindeutig bestimmte normierte Erzeuger von
	$ \mathcal{A} (T) $ 
	ist das \textbf{minimal Polynom von $ T $} und wird mit $ \operatorname{Min Pol} T $ bezeichnet.
\end{subdefinition}

\begin{subnote}
	\begin{enumerate}[label=(\arabic*)]
		\item $ \deg (\operatorname{Min Pol}(T)) \leq  n^2 $
		\item $ p = \operatorname{Min Pol}(T) $ ist Charakterisiert durch
			\begin{enumerate}[label=(\alph*)]
				\item $ p \in K[x] $ 
				\item $ p(T) = 0 $ 
				\item $ \forall q \in K[x] : \deg q < \deg p \implies q(T) \neq 0  $
			\end{enumerate}
	\end{enumerate}
\end{subnote}

\begin{subdefinition}
	für ein $ A \in Mat_{n \times n} (K) $ sind $ \mathcal{A} (A) $ und $ \operatorname{Min Pol}(A) $ analog definiert
\end{subdefinition}

\begin{subnote}
	\begin{enumerate}[label=(\arabic*)]
		\item Sei $ \mathcal{B}  $ eine geordnete Basis von $ V $ und $ f \in K[x] $.
			Es gilt $ [f(T)]_{\mathcal{B} } = f\left( [T]_{\mathcal{B} }  \right)  $ 
			Insbesondere für $ A = [T]_{\mathcal{B} }  $ gilt
			\[
				f(T) = 0 \iff f(A) = 0
			\]
		\item Es folgt: ähnliche Matrizen haben das gleiche minimale Polynom!
	\end{enumerate}
\end{subnote}

\begin{subtheorem}
	Sei $ T \in \mathcal{L} (V, V) $ (oder $ A \in Mat_{n \times n} (K) $.
	Es gilt: $ \operatorname{Char Pol}(T)  $ und $ \operatorname{Min Pol}(T) $ haben, bis auf Vielfachheit, dieselben Nullstellen in $ K $
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.19.6}]
	Sei $ p \coloneqq \operatorname{Min Pol}(T) $ und $ c \in K $.
	Zu zeigen $ p(c) = 0 \iff c $ ist Eigenwert von $ T $ 
	\begin{description}
		\item[``$ \implies  $'':] $ p(c) = 0 \implies p = (x - c) q $.
			\[
				\deg q < \deg p
			\]
			Also ist $ q(T) \neq 0 $.
			Also wähle $ \beta \in V $ so, dass $ \alpha \coloneqq  q(T) (\beta) \neq 0 $ 
			Es gilt $ 0 = p(T)(\beta) = (T - cI)(qT)(\beta) = (T - cI)(\alpha) $
			Also ist $ \alpha $ Eigenvektor und $ c $ Eigenwert
		\item[``$ \impliedby  $'':] Sei $ T(\alpha) = c \alpha $, $ \alpha \neq 0, \alpha \in V, c \in K $ 
			Nun gilt: $ p(T)(\alpha) \overset{\text{ÜB} }{=} p(c) \alpha = 0 $.
			Da aber $ p(T) = 0 $ und $ \alpha \neq 0 $, folgt $ p(c) = 0 $\qed
	\end{description}
\end{subproof*}

\begin{subproposition}
	Sei $ T $ diagonalisierbar. Dann zerfällt das $ \operatorname{Min Pol}(T) $ (über $ K $) in verschiedene lineare Faktoren
\end{subproposition}
\begin{subproof*}[Proposition \ref{3.19.7}]
	Sei $ T $ diagonalisierbar und $ c_1, \dotsc, c_k \in K $ die verschiedenen Eigenwerte.
	Setze $ p \coloneqq \operatorname{Min Pol} T $.
	Wegen Satz \ref{3.19.6} ist $ \deg p \geq k $.
	Betrachte $ q(x) \coloneqq \left( x - c_1 \right) \dotsb \left( x - c_k \right)  $.
	Wir berechnen:
	\[
		\left( T - c_1 I \right) \dotsb \left( T - c_k I \right) (\alpha) = 0
	\]
	für $ \alpha $ Eigenvektor $ \in V $ (weil $ \alpha $ Eigenvektor zum Eigenwert $ c_i $, für geeignetes $ i $).
	Da es eine Basis gibt bestehend aus Eigenvektoren für $ T $.
	Also $ q(T) $ verschwindet auf dieser Basis der Eiegnvektoren.
	Das impliziert
	\[
		q(T) = 0
	\]
	Also $ q(x) \in \operatorname{Annihilator}(T) $ 
	Es folgt nun aus Bemerkung \ref{3.19.3} $ \deg q = k \leq  \deg p $ und $ q $ ist normiert, folgt $ q(x) = p(x) $
\end{subproof*}

\begin{subexample}
	Wir berechnen $ \operatorname{Min Pol} A \coloneqq p $ für $ A $ im Beispiel \ref{3.17.9} (ii)
	\[
		\operatorname{Char Pol}(A) = (x - 1)(x - 2)^2
	\]
	$ A $ ist \textbf{nicht} diagonalisierbar.
	Also hier können wir \textbf{nicht} Proposition \ref{3.19.7} anwenden.
	Aber wir können Satz \ref{3.17.6} anwenden.
	Also $ p $ die Nullstellen $ 1 $ und $ 2 $ hat.
	Wir probieren Polynome der Form
	\[
		\left( x - 1 \right) ^{k} \left( x - 2 \right) ^{l} 
	\]
	mit $ k \geq 1, l \geq 1, 2 \leq k + l \leq 3^2 = 9 $ 
	Wir probieren $ k = l = 1 $ 
	\[
		\left( A - I \right) \left( A - 2I \right) = \begin{pmatrix} 2 & 0 & -1 \\ 2 & 0 & -1 \\ 4 & 0 & - 2 \end{pmatrix} 
	\]
	Also ist $ \deg (p) \geq 3 $.
	Nun probieren wir:
	\[
		\left( x - 1 \right) ^2 \left( x - 2 \right) \text{oder} 
	\]
	\[
		\left( x - 1 \right) \left( x - 2 \right) ^2
	\]
	Wir berechnen:
	\[
		\left( A - I \right) \left( A - 2I \right) ^2 = 0
	\]
	Also ist $ p(x) = \left( x - 1 \right) \left( x - 2 \right) ^2 \implies \operatorname{Min Pol} A = \operatorname{Char Pol} A$ .\qed
\end{subexample}

\subsection{Skript 20}
\begin{subtheorem}[von Cayley Hamilton]
	Sei $ \dim V = n, L \in \mathcal{L} \left( V, V \right) $
	\[
		f \coloneqq \operatorname{Char Pol}(L).
	\]
	Es gilt $ f(L) = 0 $.
	Insbesondere teilt $ \operatorname{Min Pol}(L) $ das $ \operatorname{Char Pol}(L) $
\end{subtheorem}
\begin{subproof*}[Satz von Cayley Hamilton \ref{3.20.1}]
	Sei $ \mathcal{K}  $ die Algebra der Polynome in $ L $ und $ \mathcal{B} = \left( \alpha_1, \dotsc, \alpha_n \right)  $ für $ V $.
	Setze
	\[
		A \coloneqq  [L]_{\mathcal{B} } 
	\]
	d.h.
	\[
		L(\alpha_i) = \sum_{j=1}^{n} A_{ji} \alpha_j
	\]
	$ \forall i \leq i \leq n $ 
	\begin{itemize}
		\item Wir schreiben diese um, als
			\begin{equation}
				\label{eq:Satz von Cayley Hamilton.1}
				\tag{$ 1 $}
				\sum_{j=1}^{n} \left( \delta_{ij} L - A_{ji} I \right) (\alpha_j) = 0 \quad \forall 1 \leq i \leq n
			\end{equation}
			Sei $ B $ die $ n \times n $ Matrix mit den Koeffizienten in $ \mathcal{K}  $ definiert durch
			\[
				B_{ij}  = S_{ij} L - A_{ji} I
			\]
			\textbf{Beh.:}
			\[
				\det B = f(L) \text{ und} 
			\]
			\[
				\det B = 0
			\]
		\item Wir haben $ f(x) = \det\left( xI - A \right) = \det \left( xI - A \right)^t $.
			Wir berechnen
			\[
				\left( xI - A \right) _{ij} ^t = \delta_{ij} x - A_{ji} 
			\]
			Also gilt:
			\[
				\left( xI - A \right) _{ij} ^t (L) = \delta_{ij} L - A_{ji} I = B_{ij} 
			\]
			Außerdem gilt:
			\begin{align*}
				f(L) &= \left[ \det \left( xI - A \right)  \right] (L) \\
				~ &= \left[ \det \left( xI - A \right) ^{t}  \right] (L) \\
				~ &= \det \left(  \left( xI - A \right) ^{t} (L) \right)  \\
				~ &= \det B.
			\end{align*}
		\item Wir zeigen $ \det B = 0 $. Dafür genügt es zu zeigen, dass
			\[
				\left( \det B \right) \left( \alpha_k \right) = 0 \quad k = 1, \dotsc, n
			\]
			Wegen \eqref{eq:Satz von Cayley Hamilton.1} gelten $ B_{ij}  $ und $ \alpha_j $:
			\begin{equation}
				\label{eq:Satz von Cayley Hamilton.2}
				\tag{$ 2 $}
				\sum_{j=1}^{n} B_{ij} (\alpha_j) = 0 \quad \forall 1 \leq i \leq n
			\end{equation}
		\item Setze $ \tilde B = \adj B $ 
			Aus \eqref{eq:Satz von Cayley Hamilton.2} folgt, für alle $ k $ und $ i $ 
			\[
				\tilde B_{ki} \left( \sum_{j=1}^{n} B_{ij} \alpha_j \right) = 0 = \sum_{j=1}^{n} \tilde B_{ki} B_{ij} \alpha_j
			\]
			Wir summieren über $ i $ und bekommen
			\[
				0 = \sum_{i=1}^{n} \sum_{j=1}^{n} \tilde B_{ki} B_{ij} \alpha_j = \sum_{j=1}^{n} \underbrace{\left( \sum_{i=1}^{n} \tilde B_{ki} B_{ij}  \right) }_{\text{$ kj $-te Koef von $ \tilde B B $} } \left( \alpha_j \right) 
			\]
	\end{itemize}
\end{subproof*}

\subsubsection{Trigonalisierbarkeit}
Sei $ V $ endlich dimensional $ K $-VR
\begin{subdefinition}
	$ T \in \mathcal{L} (V, V) $ ist trigonalisierbar falls es eine Basis $ \mathcal{B}  $ für $ V $ gibt so dass $ [T]_\mathcal{B}  $ eine obere $ \triangle $-Matrix ist (d.h. $ a_{ij} = 0 $ für $ i > j $)
\end{subdefinition}

\begin{subtheorem}
	Es gilt:
	$ T $ ist trigonalisierbar $ \iff \operatorname{Char Pol}(T) $ zerfällt in linear-Faktoren über $ K $,
	(d.h. $ \operatorname{Char Pol}(T) = \left( x - c_1 \right) ^{n_1} \dotsb \left( x - c_k \right) ^{n_k}  $ mit $ c_i \in K $)
\end{subtheorem}
\begin{subproof*}[Satz \ref{3.20.3}]
	\begin{description}
		\item[``$ \implies  $'']
			$ [T]_{\mathcal{B} } = A $ $ \triangle $-Matrix $ \implies \det \left( xI - A \right) = \prod_{i = 1}^{n} \left( x - a_{ii}  \right)   $.
		\item[``$ \impliedby  $'']
			Wir beweisen per Induktion über $ \dim V = n $ eine Basis $ \mathcal{B} = \left( \alpha_1 , \dotsc, \alpha_n \right)  $ aufbauen wofür $ [T]_{\mathcal{B} }  $ eine $ \triangle $-Matrix ist.
			Da $ T $ mindestens ein Eigenwert $ c_1 \in K $ hat, sei $ \alpha \neq 0 $ ein Eigenvektor $ \left\{ \alpha \right\}  $ linear unabhängig $ \overset{\text{Basis Ergänzung} }{\implies } \left( \alpha, \beta_2, \dotsc, \beta_n \right)  $ für $ V $, Matrixdarstellung von $ T $ in dieser Basis
			\begin{equation}
				\label{eq:3.20.3.1}
				\tag{$ * $}
				\left( 
					\begin{array}{c | c c c}
						c_1 & a_{12} & \hdots a_{1n} \\ \hline
						0 & a_{22} & \hdots a_{2n} \\
						\vdots \\
						0 & a_{n2} & \hdots a_{nn} \\
					\end{array}
				\right) 
			\end{equation}
			\[
				\Gamma \in M_{(n - 1) \times (n - 1)} (K)
			\]
			Setze $ W = \Span \left\{ \beta_2, \dotsc, \beta_n \right\}  $ definiere $ G \in \mathcal{L} \left( W, W \right)  $ 
			\[
				G w = \Gamma w \text{ für alle $ w \in W $} 
			\]
			Wir sehen aus \eqref{eq:3.20.3.1} $ \operatorname{Char Pol}(T) = (x - c_1) \operatorname{Char Pol}(G) $\\
			Eindeutigkeit der Faktoren in $ K[x] $, folgt $ \operatorname{Char Pol}(G) $ Produkt von linearen Faktoren.
			I.A. liefert nun eine geordnete Basis $ \left( \alpha_1, \dotsc, \alpha_n \right)  $ so, dass die Matrixdarstellung von $ G $ eine obere $ \triangle $-Matrix ist\qed
	\end{description}
\end{subproof*}

\subsection{Skript 21}
\setcounter{subsubsection}{11}
\subsubsection{Invariante Unterräume}

\begin{subdefinition}
	Sei $ W \subseteq V $ ein Unterraum und $ T \in \mathcal{L} (V, V) $.
	Dann ist $ W $ \textbf{T-invariant} falls $ T(W) \subseteq W $
\end{subdefinition}

\begin{subexample}
	\begin{enumerate}[label=(\arabic*)]
		\setcounter{enumi}{-1}
		\item $ \left\{ 0 \right\}  $, und $ V $ sind $ T $-invariant für aale $ T \in \mathcal{L} (V, V) $.
		\item Sei $ D $ der Ableitung Operator auf $ V \coloneqq K[x] $ und $ W = K[x] \leq d $.
			Dann ist $ W $ $ T $-invariant
		\item Sei $ U \subset \mathcal{L} (V, V) $ so, dass $ TU = UT $, setze
			\begin{enumerate}[label=(\alph*)]
				\item $ W = \Bild (U) $ 
				\item $ N = \ker (U) $
			\end{enumerate}
			Dann sind $ W $ und $ N $ $ T $-invariant
			\begin{subproof*}
				\begin{enumerate}[label=(\alph*)]
					\item Sei $ \alpha \in \Bild (U) $, $ \exists \beta $ so, dass $ \alpha = U(\beta) $.
						\[
							T(\alpha) = T\left( U\left( \beta \right)  \right) = U\left( T\left( \beta \right)  \right) \in \Bild U
						\]
					\item Sei $ \alpha \in N $, berechne $ U\left( T\left( \alpha \right)  \right) = t\left( U\left( \alpha \right)  \right) = T(0) = 0 \implies T(\alpha) \in N $\qed
				\end{enumerate}
			\end{subproof*}
		\item $ W \subseteq V $ ist $ T $-invariant $ \implies  $ $ W $ ist $ g(T) $-invariant für alle $ g(x) \in K[x] $ ÜB
		\item Für alle $ g \in K[x] $ gilt
			\[
				g(T) T = T g(T) \text{(\textbf{ÜA})}
			\]
			Insbesondere gilt $ g(T) = cI - T $.
			Daraus folgt wegen (2) $ \ker (T - cI) $ $ T $-invariant,
			d.h. der Eigenraum zum Eigenwert $ c \in K $ ist $ T $-invariant.
	\end{enumerate}
\end{subexample}

\begin{itemize}
	\item \textbf{Der Operator $ T_w $}:
		sei $ T \in \mathcal{L} (V, V) $, $ W \subseteq V $ ist $ T $-invariant.
		setze
		\[
			T|_W \coloneqq T_W
		\]
		\[
			T_W : W \to W,
		\]
		also ist
		\[
			T_W \in \mathcal{L} (W, W)
		\]
	\item[$ \dagger $]
		\label{Matrix Darstellung für TW}
		Matrix Darstellung für $ T_W $:
		Sei $ W \subseteq V $ $ T $-invariant mit $ \dim W = r $.
		Sei $ \mathcal{B} ^\prime = \left( \alpha_1, \dotsc, \alpha_r \right)  $ 
		eine geordnete Basis für $ W $.
		Ergänze $ \mathcal{B} ^\prime  $ zu einer Basis $ \mathcal{B} = \left( \alpha_1, \dotsc, \alpha_r, \alpha_{r + 1} , \dotsc, \alpha_n \right)  $ für $ V $.
		Betrachte $ A = [T]_{\mathcal{B} }  $ Wir haben die Gleichungen
		\[
			T(\alpha_j) = \sum_{i=1}^{n} A_{ij} \alpha_i
		\]
		Da $ W $ $ T $-invariant ist, sind $ T\left( \alpha_j \right) \in W $ für $ j \leq r $
		Also
		\[
			T(\alpha_j) = \sum_{i=1}^{r} A_{ij} \alpha_i
		\]
		Das heißt $ A_{ij} = 0 $ für $ j \leq r $ und $ i > r $
		Also sieht $ A $ so aus
		\[
			A = \begin{pmatrix} B & C \\ 0 & D \end{pmatrix} 
		\]
		wobei $ B : r \times r $, $ C : r \times (n - r) $, $ D : \left( n - r \right) \times \left( n - r \right)  $ und $ B = \left[ T_W \right]_{\mathcal{B} ^\prime }  $.
\end{itemize}

\begin{sublemma}
	Sei $ T \in \mathcal{L} (V, V) $  $ W \subseteq V $, $ T $-invariant.
	Es gelten:
	\begin{enumerate}[label=(\alph*)]
		\item $ \operatorname{Char Pol} T_W $ teilt $ \operatorname{Char Pol} T $ 
		\item $ \operatorname{Min Pol} T_W $ teilt $ \operatorname{Min Pol} T $ 
	\end{enumerate}
\end{sublemma}
\begin{subproof*}[Lemma \ref{3.21.3}]
	Seien $ \mathcal{B} ^\prime  $ und $ \mathcal{B}  $ so gewählt wie in ($ \dagger $), in $ A $ und $ B $ wie in ($ \dagger $) ÜB $ \implies  $ 
	\begin{enumerate}[label=(\roman*)]
		\item
			\[
				\underbrace{\det \left( xI - A \right) }_{\operatorname{Char Pol} T} = \underbrace{\det \left( xI - B \right) }_{\operatorname{Char Pol} T} \det \left( xI - D \right) \qed
			\]
		\item
			\[
				A^k = \begin{pmatrix} B^k & C_k \\ 0 & D^k \end{pmatrix} 
			\]
			wobei $ C_k $ eine $ r \times \left( n - r \right)  $-Matrix für $ k \in \N_0  $.
	\end{enumerate}
	Es folgt daraus, dass ein Polynom $ q \in \operatorname{Annihilator}(A) $ ist $ q $ auch $ \in \operatorname{Annihilator} (B) $.
	Also teilt $ \operatorname{Min Pol} B $ das $ \operatorname{Min Pol} A $. \qed
\end{subproof*}

\subsection{Skript 22}
\begin{sublemma}
	Sei $ W \subseteq V $ ein Unterraum, sei $ \mathcal{B} ^\prime  $ eine geordnete Basis für $ W $, und
	\[
		\mathcal{B} ^\prime \cup \mathcal{B} ^{\prime\prime} 
	\]
	eine ergänzende Basis für $ V $.
	Dann gelten
	\begin{enumerate}[label=(\roman*)]
		\item $ \overline{\mathcal{B} ^{\prime\prime}}  $ ist eine Basis für $ V / W $ 
		\item Umgekehrt, wenn $ \left( \overline{\beta_{r + 1} }, \dotsc, \overline{\beta_n}  \right)  $ eine geordnete Basis für $ V / W $ ist, dann ist
			\[
				\mathcal{B} ^\prime  \cup \left\{ \beta_{r + 1} , \dotsc, \beta_n \right\} 
			\]
			ist eine Basis für $ V $.\qed
	\end{enumerate}
\end{sublemma}

\begin{subnote*}
	Sei $ W \subseteq V $ $ T $-invariant.
	Dann ist die Abbildung
	\[
		\overline{T} : V / W \to V / W
	\]
	so definiert
	\[
		\overline{T} \left( \overline{\alpha}  \right) \coloneqq \overline{T ( \alpha )} 
	\]
	ist wohldefiniert und ist linear.
	Also ist $ \overline{T} \in \mathcal{L} \left( V / W, V / W \right)  $.
	\begin{subproof*}
		\begin{description}
			\item[``wohldefiniert'':] Zu zeigen
				$ \overline{\alpha_1} = \overline{\alpha_2} \implies  \overline{T(\alpha_1)} = \overline{T\left( \alpha_2 \right) } $\\
				\textbf{Bew.:}
				$ \alpha_1 - \alpha_2 \in W \implies T(\alpha_1 - \alpha_2) \in W \implies T(\alpha_1) - T(\alpha_2) \in W \implies \overline{T(\alpha_1)} = \overline{T(\alpha_2)}  $\qed
		\end{description}
	\end{subproof*}
\end{subnote*}

\begin{subtheorem}
	Sei $ W \subseteq V $ $ T $-invariant $ \mathcal{B} ^\prime  $ geordnete Basis für $ W $, ergänzt
	\[
		\mathcal{B} = \mathcal{B} ^\prime \cup \mathcal{B} ^{\prime\prime} 
	\]
	von $ V $.
	Es gilt
	\[
		A = [T]_\mathcal{B} = \begin{pmatrix} B & C \\ 0 & D \end{pmatrix} 
	\]
	wobei $ D = \left[ \overline{T}  \right]_{\overline{\mathcal{B} ^{\prime\prime} } }  $ 
	und $ \mathcal{B} = \left[ T_W \right]_{\mathcal{B} ^\prime }  $.
\end{subtheorem}
\begin{subproof}[Satz \ref{3.22.2}]
	\begin{equation}
		\label{3.22.2.1}
		\tag{$ * $}
		T(\alpha_i) = \sum_{j=1}^{n} A_{ji} \alpha_j \quad \text{für $ 1 \leq i \leq n $} 
	\end{equation}
	\[
		A =
		\left( 
			\begin{array}{c|c|c|c}
				B & A_{1, r + 1} & & \\\cline{1-1}
				  & \vdots & & \\
				  & A_{r, r + 1} & & \\
				  & \vdots & & \\
				  & A_{n, r + 1} & &
			\end{array}
		\right) 
	\]
	\begin{equation}
		\label{3.22.2.2}
		\tag{$ ** $}
		T(\alpha_i) = \sum_{j=1}^{r} A_{ji} \alpha_j \quad \text{für $ 1 \leq i \leq n $} \sum_{j=r + 1}^{n} A_{ji} \alpha_j \quad \text{für $ 1 \leq i \leq n $} 
	\end{equation}
	\textbf{Also ist}
	\[
		\overline{T(\alpha_i)} = \sum_{j=r + 1}^{n} A_{ji} \overline{\alpha_j} = \overline{T} \left( \overline{\alpha_j}  \right) 
	\]
	für $ r + 1 \leq  i \leq n $\qed
\end{subproof}

\begin{subcorollary}
	$ \operatorname{Char Pol} T = \left( \operatorname{Char Pol} T_W \right) \left( \operatorname{Char Pol} \overline{T}  \right)  $
\end{subcorollary}

Ziel ist es Korollar \ref{3.22.6} zu beweisen\\
Hintergrund: in Satz \ref{3.20.3} hatten wir bewiesen $ V $ end. dim. VR, $ T \in \mathcal{L} (V, V) $.\\
$ T $ ist \textbf{trigonalisierbar} genau dann, wenn \textbf{$ \operatorname{Char Pol} T $} im Produkt von linearen Faktoren über $ K $ zerfällt.
{
	\color{gadse-red} Kor. \ref{3.22.6} gibt uns dieselbe Charakterisierung mithilfe von
	\[
		\operatorname{Min Pol} T
	\]
	anstatt
	\[
		\operatorname{Char Pol} T
	\]
}

\setcounter{subenvironmentnumber}{5}
\begin{subcorollary}
	Sei $ K $ Körper, $ T \in \mathcal{L} (V, V) $, $ V $ endlich dimensionaler Vektorraum.
	Dann ist $ T $ trigonalisierbar genau dann, wenn $ \operatorname{Min Pol} T $ im Produkt von linearen Faktoren über $ K $ zerfällt.
\end{subcorollary}

\begin{subproposition*}
	Sei $ K $ Körper, $ V $ endl. $ K $-VR, $ T \in \mathcal{L} (V, V) $\\
	\textbf{Es gilt:} $ \operatorname{Char Pol} T $ zerfällt im Produkt von linearen Faktoren über $ K $ genau dann, wenn $ \operatorname{Min Pol} T $ zerfällt im Produkt von linearen Faktoren über $ K $.
\end{subproposition*}

Für den Beweis der Proposition brauchen wir ein Konzept und Aussage, die wir erst in der Vorlesung Algebra I im Wintersemester 2024 beweisen werden.

\begin{subdefinition}
	Sei $ K $ ein Körper und $ p \in K[x] $, $ \deg p = n $, $ n \in \N  $.
	Eine Körpererweiterung
	\[
		Z | K
	\]
	ist ein \textbf{Zerfällungskörper für $ p $}, wenn $ p(x) $ zerfällt im Produkt von linearen Faktoren über $ Z $.
	Das heißt $ \exists l_i \in \N  $, $ c_i \in \Z  $ und $ l \in \N  $ so, dass
	\begin{equation}
		\label{eq:Faktorisierung}
		\tag{$ * $}
		p(x) = \prod_{i = 1}^{l} (x - c_i)^{l_i}  
	\end{equation}
	
	Das heißt, $ c_1, \dotsc, c_l $ sind Nullstellen von $ p $ und
	\[
		\sum_{i=1}^{l} l_i = n
	\]
\end{subdefinition}

\begin{subtheorem*}
	Sei $ K $ ein Körper, $ p \in K[x], \deg p \in \N  $.
	Dann gibt es ein Zerfällungskörper $ Z | K $ für $ p $.
	\begin{subproof*}
		VL Algebra I
	\end{subproof*}
\end{subtheorem*}

\begin{subproof*}[Proposition]
	Sei $ Z | K $ ein Zerfällungskörper von
	\[
		\operatorname{Char Pol}_K T.
	\]
	Dann sind die NS von $ \operatorname{Char Pol}_Z T $ die $ c_1, \dotsc, c_l $ wie in der Faktorisierung \eqref{eq:Faktorisierung}.
	Wir haben aber bewiesen, dass $ \MinPol_Z T $ und $ \CharPol_Z T $ dieselbe Nullstelle in $ Z $ haben.
	Insbesondere ist $ Z $ auch ein Zerfällungskörper für $ \MinPol_Z T $.
	Das heißt wiederum, das $ \MinPol_Z T $ im Produkt von linearen Faktoren und umgekehrt zerfällt:
	wenn $ \MinPol_Z T $ in Produkt von linearen Faktoren in $ Z $ zerfällt, dann ist $ Z $ Zerfällungskörper für $ \CharPol_Z T $, also zerfällt $ \CharPol_Z T $ in Produkt von linearen Faktoren wie in \eqref{eq:Faktorisierung}.\\
	Aber
	\begin{align*}
		\CharPol_Z T &= \CharPol_K T \\
		\MinPol_Z T &= \MinPol_K T \\
	\end{align*}
\end{subproof*}

\begin{subcorollary}[Charakterisierung von Trigonalisierbarkeit]
	Sei $ K $ ein Körper, $ V $ ednl dim. $ K $-VR, und $ T \in \mathcal{L} (V, V) $.
	Es gilt:
	$ T $ ist trigonalisierbar über $ K $ genau dann, wenn $ \CharPol T $ zerfällt über $ K $ genau dann wenn $ \MinPol T $ zerfällt über $ K $
\end{subcorollary}

\subsection{Skript 23}
\setcounter{subsubsection}{12}
\subsubsection{Direkte Summe und Primzerlegung}
\begin{sublemma}
	Sei $ V $ $ K $-VR, $ W_1, \dotsc, W_k $ Unterräume von $ V $.
	Die folgende Aussagen sind äquivalent.
	\begin{enumerate}[label=(\roman*)]
		\item $ W_1, \dotsc, W_k $ sind unabhängig, d.h. sei $ \alpha_i \in W_i $ für $ 1 \leq i \leq k $ so, dass
			\[
				\sum_{i=1}^{k} \alpha_i = 0,
			\]
			dann ist $ \alpha_i = 0 $ $ \forall i = 1, \dotsc, k $.
		\item 
			\[
				W_j \cap \left( W_1, \dotsc, W_j \right) = \left\{ 0 \right\} \text{ für }  2 \leq j \leq k
			\]
		\item Ist $ \mathcal{B} _i $ eine Basis für $ W_i $, dann ist
			\[
				\mathcal{B} = \bigcup_{i = 1} ^{k} \mathcal{B} _I
			\]
			eine Basis für $ W_1 + \dotsb + W_k $\qed
	\end{enumerate}
\end{sublemma}

\begin{subdefinition*}[Notation und Terminologie]
	Wir schreiben $ V = W_1 + \dotsb + W_k $, wenn $ V $, die \textbf{Summe} von Unterräumen $ W_i $ ist, und wir schreiben
	\[
		V = W_1 \oplus \dotsb \oplus W_k
	\]
	wenn die Unterräume $ W_1, \dotsc, W_k $ die Bedingungen von Lemma \ref{3.23.1} erfüllen und sagen $ V $ ist die \textbf{direkte Summe}.
\end{subdefinition*}
T
\begin{subtheorem}[Primzerlegung von $ V $ bezüglich Primfaktorisierung $ \MinPol $ T]
	Sei $ V $ endl dim über $ K $, $ T \in \mathcal{L} (V, V) $.
	Setze $ \MinPol T = p = p_1^{r_1} \dotsb p_k^{r_k}  $ die Primfaktorisierung in $ K[x] $ 
	(wobei $ p_i $ verschiedene normierte irreduzible Polynome in $ K[x] $ sind und $ r_i \in \N  $)
	Setze $ W_i = \Kern p_i (T) ^{r_i}  $ für $ 1 \leq i \leq k $.
	Dann sind $ W_i $, für $ 1 \leq i \leq k $, $ T $-invariante Unterräume, und darüber hinaus gelten
	\begin{enumerate}[label=(\roman*)]
		\item $ V = W_1 \oplus \dotsb \oplus W_k $ 
		\item $ \MinPol T_{W_i} = p_i^{r_i}  $ für $ 1 \leq i \leq k $.
	\end{enumerate}
\end{subtheorem}

\begin{subproposition}
	Sei $ V $ endl dim $ K $-VR $ T \in \mathcal{L} (V, V) $.
	$ \MinPol T = m = m_1 m_2 $ mit $ \ggT(m_1, m_2) = 1 $
	Setze $ V_1 = \Kern m_i (T) $ für $ i = 1, 2 $.
	Es gelten: $ V_1, V_2 $ sind $ T $-invariant und $ V = V_1 \oplus V_2 $ und $ \MinPol T_{V_i} = m_i $ für $ i = 1, 2 $
\end{subproposition}
\begin{subproof*}[Proposition \ref{3.23.3}]
	Da $ m_1, m_2 $ relativprim sind $ \exists q_1, \dotsc, q_2 \in K[x] $ so, dass 
	\[
		1 = m_1 q_1 + m_2 q_2
	\]
	oder
	\begin{equation}
		\label{eq:3.23.3.1}
		\tag{$ * $}
		I = m_1(T) q_1(T) + m_2(T) q_2(T)
	\end{equation}
	\textbf{Beh 1:} $ V_1 = I_m  m_2(T) $ und $ V_2 = I_m m_1(T) $\\
	\textbf{Bew.:} $ 0 = m(T) = m_1(T) m_2(T) $, also $ I_m m_2(T) \subseteq \Kern m_1(T) $ 
	umgekehrt $ v \in \Kern m_1(T) $, gilt wegen \eqref{eq:3.23.3.1}
	\[
		v = \underbrace{q_1(T) m_1(T)(v)}_{= 0} + \underbrace{m_2(T) \left( q_2(t) \right) (v)}_{\in I_m m_2(v)}
	\]
	\textbf{Beh. 2} $ V = V_1 \oplus V_2 $\\
	\textbf{Bew.:}
	\begin{enumerate}[label=(\arabic*)]
		\item Summe:\\
			Sei $ v \in V $, wegen \eqref{eq:3.23.3.1} schreibe
			\[
				v = \underbrace{m_1(T) q_1(T)(v)}_{\in I_m m_1} + \underbrace{m_2(T)q_2(T)(v)}_{\in I_m m_2(T)} 
			\]
		\item direkt:\\
			Sei $ v \in V_1 \cap V_2 $, wegen \eqref{eq:3.23.3.1} gilt $ v = \underbrace{q_1(T) m_1(T)(v)}_{ = 0}  + \underbrace{q_2(T) m_2(T)(v)}_{= 0}  $.
			Sei nun \ldots
	\end{enumerate}
	Da $ V_i = \Kern m_i(T) $ für $ i = 1, 2 $ ist es klar, dass $ m_i\left( T_{V_i}  \right) = 0 $, d.h.
	\begin{equation}
		\label{eq:3.23.3.2}
		\tag{$ * * $}
		\tilde m_1 | m_1 \text{ und } 
		\tilde m_2 | m_2
	\end{equation}
	\textbf{Beh. 3:} $ \tilde m_1 \tilde m_2 $ annihiliert $ T $
	\textbf{Bew.:} Seien $ v_1 \in V_1 $ und $ v_2 \in V_2 $, $ v = v_1 + v_2 \in V $, rechne
	\begin{align*}
		\tilde m_1(T) \tilde m_2 (T) (v_1 + v_2 &= 
		\tilde m_1(T) \left[ \tilde m_2 (T) (v_2) + \tilde m_2 (T) (v_1) \right]\\
		~ &= \tilde m_1(T) \left[ 0 + \underbrace{\tilde m_2 (T) (v_1)}_{\in V_1 \text{ weil Bsp \ref{3.20.2} (4)} } \right]\\
		~ &= 0
	\end{align*}
	Da $ \tilde m_2 \tilde m_1 $ annihiliert $ T $ $ \implies m_1m_2 | \tilde m_1 \tilde m_2 $.
	Aber $ m_1, m_2 $ sind normiert folgt nun aus \eqref{eq:3.23.3.2}, dass $ \tilde m_1 = m_1 $ und $ \tilde m_2 = m_2 $\qed
\end{subproof*}


